{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페이지 추출함수\n",
    "def pageExtraction(url1):\n",
    "  webpage = requests.get(url1)\n",
    "  soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "  # #논문 제목,링크 추출\n",
    "  df_data1 = []\n",
    "  df_name = []\n",
    "  df_link = []\n",
    "  df_link1 = []\n",
    "  division = []\n",
    "  data1s = soup.select('#main > div > div > div > a > div')\n",
    "  data2s = soup.select('#main > div > div > div > a > h3 > div')\n",
    "\n",
    "  for i, data in enumerate(data1s):\n",
    "    if i%2 == 0:\n",
    "      st = str(data1s[i]).find('>')\n",
    "      end = str(data1s[i]).find('</')\n",
    "      df_link1.append((str(data1s[i])[st+1:end]))\n",
    "\n",
    "  for i, data in enumerate(data2s):\n",
    "    st = str(data2s[i]).find('>')\n",
    "    end = str(data2s[i]).find('</')\n",
    "    df_name.append((str(data2s[i])[st+1:end-1]))\n",
    "\n",
    "  #링크에서 외국어처리되는 부분 삭제\n",
    "  for link in df_link1:\n",
    "    if link.find('?')!=-1:\n",
    "      df_link.append(link[:-6])\n",
    "    else :\n",
    "      df_link.append(link)\n",
    "\n",
    "  # #특허번호와 국가코드 추출\n",
    "  df_patent = []\n",
    "  df_code = []\n",
    "  if (df_link[0].find('www.google.com') != -1):\n",
    "    for link in df_link:\n",
    "      df_patent.append(link.replace('www.google.com/patents/',''))\n",
    "      df_code.append(link.replace('www.google.com/patents/','')[0:3])\n",
    "  elif (df_link[0].find('www.google.co.kr') != -1):\n",
    "    for link in df_link:\n",
    "      df_patent.append(link.replace('www.google.co.kr/patents/',''))\n",
    "      df_code.append(link.replace('www.google.co.kr/patents/','')[0:3])\n",
    "    #국가코드 3자리인 경우도 포함하기 위하여 3자리에서 숫자아닌경우 slicing\n",
    "  for i,code in enumerate(df_code):\n",
    "   if str.isdigit(code[2:3]):\n",
    "      df_code[i]=(code[0:2])\n",
    "   else :\n",
    "      df_code[i]=(code[0:3])\n",
    "\n",
    "  #for dataframe\n",
    "  df = pd.DataFrame(index=range(0,len(df_data1)), columns=['특허제목', '링크', '특허번호','국가코드'])\n",
    "  df['특허제목'] = df_name\n",
    "  df['링크'] = df_link\n",
    "  df['특허번호'] = df_patent\n",
    "  df['국가코드'] = df_code\n",
    "  return df\n",
    "\n",
    "# 적용국가 추출함수\n",
    "def application(url):\n",
    "  data = requests.get(url)\n",
    "  soup = BeautifulSoup(data.content, 'html.parser')  \n",
    "  country = soup.find_all('span', attrs={'itemprop': 'countryCode'})\n",
    "  Date = soup.find_all('span', attrs={'itemprop': 'filingDate'})\n",
    "  nation_name = []\n",
    "  nation_date = []\n",
    "  # ----------------특허 적용 국가 리스트----------------\n",
    "  for n in country:\n",
    "       nation_name.append(n.get_text())\n",
    "  country_name =  [] \n",
    "  for i in nation_name:\n",
    "     country_name.append(i)\n",
    "  for n in Date:\n",
    "     nation_date.append(n.get_text())\n",
    "  country_date =  [] \n",
    "  for i in nation_date:\n",
    "      country_date.append(i)\n",
    "  del country_date[0]\n",
    "\n",
    "  new_contryName = []\n",
    "  new_contryDate = []\n",
    "  for i,v in enumerate(country_date):\n",
    "    new_contryDate.append(v[:4])\n",
    "  for i in range(len(new_contryDate)):\n",
    "    new_contryName.append(country_name[-1-i])\n",
    "  new_contryName.reverse()\n",
    "\n",
    "  df_application = []\n",
    "  for i in range(len(new_contryName)):\n",
    "    df_application.append(new_contryName[i]+'('+new_contryDate[i]+')')\n",
    "\n",
    "  df_output = []\n",
    "  df_output.append(' / '.join(df_application))\n",
    "\n",
    "  inventor = soup.find_all('dd',{'itemprop':'inventor'})\n",
    "  assigneeCurrent = soup.find_all('dd',{'itemprop':'assigneeCurrent'})  \n",
    "  patent_inventor = []\n",
    "  patent_assignee = []\n",
    "\n",
    "  for n in inventor:\n",
    "      patent_inventor.append(n.get_text())\n",
    "\n",
    "  df_patent_inventor = []\n",
    "  for i in range(len(patent_inventor)):\n",
    "    if i == 0:\n",
    "      df_patent_inventor.append(patent_inventor[i])\n",
    "    else :\n",
    "      df_patent_inventor.append(' / '+patent_inventor[i])\n",
    "  df_patent_inventor= \"\".join(df_patent_inventor)\n",
    "\n",
    "  for n in assigneeCurrent:\n",
    "      patent_assignee.append(n.get_text())\n",
    "  df_patent_assignee = []\n",
    "  for i in range(len(patent_assignee)):\n",
    "    if i ==0:\n",
    "      df_patent_assignee.append(patent_assignee[i])\n",
    "    else :\n",
    "      df_patent_assignee.append(' / '+patent_assignee[i])\n",
    "\n",
    "  Str_assignee = \"\".join(df_patent_assignee)\n",
    "  Str_assignee = Str_assignee.replace(\"\\n\",\"\")\n",
    "  Str_assignee = Str_assignee.lstrip()\n",
    "  new_list_assignee = Str_assignee.split(\"   \")\n",
    "  new_list_assignee= \"\".join(new_list_assignee)\n",
    "\n",
    "  df1 = pd.DataFrame(index=range(0,1), columns=['적용국가','Inventor','assignee'])\n",
    "  df1['적용국가'] = df_output\n",
    "  df1['Inventor'] = df_patent_inventor\n",
    "  df1['assignee'] = new_list_assignee\n",
    "  return df1\n",
    "\n",
    "def search(keywords, N):\n",
    "  keywords.replace(' ','+')\n",
    "  keyword = keywords.split(',')\n",
    "  baseUr1 = 'https://www.google.com/search?q='\n",
    "\n",
    "  #데이터 프레임 concat 기능\n",
    "  whole_df = pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
    "  plusUr1 = ''\n",
    "  ur1 = ''\n",
    "  for i in range(int(N/10)):\n",
    "    for key in keyword:\n",
    "      if(key != 'end'):\n",
    "        plusUr1 = plusUr1 + '%22' + key +'%22+'\n",
    "      else:\n",
    "        plusUr1 = plusUr1[:-1]\n",
    "    ur1 = baseUr1 + plusUr1 + '&tbm=pts&start=' + str(i*10)\n",
    "    plusUr1 = ''\n",
    "    df = pageExtraction(ur1)\n",
    "    whole_df = pd.concat([whole_df,df], ignore_index=True)\n",
    "  return keywords, whole_df\n",
    "\n",
    "def search_advanced(df):\n",
    "  df_app = []\n",
    "  df2 = pd.DataFrame(columns=['적용국가','Inventor','assignee'])\n",
    "  for link in df['링크']:\n",
    "    df1 = application('http://'+link)\n",
    "    df2 = pd.concat([df2, df1], ignore_index=True)\n",
    "\n",
    "  df_out = pd.concat([df,df2],axis=1)\n",
    "  return df_out\n",
    "\n",
    "def field_search(df):\n",
    "  index = df.columns.tolist()\n",
    "  print('검색가능한 field들 :',index)\n",
    "  index.append('end')\n",
    "\n",
    "  df_output = df\n",
    "  field = input('검색할 field를 입력하세요(끝내고싶으면 end 입력) : ')\n",
    "  while(field != 'end'):\n",
    "      while (field not in index):\n",
    "        field = input('검색할 field를 다시 입력하세요(끝내고싶으면 end 입력) : ')\n",
    "      key = input('검색할 키워드를 입력하세요 : ')\n",
    "      df_output = df[df[field].str.contains(key)]\n",
    "      df = df_output\n",
    "      field = input('검색할 field를 입력하세요(끝내고싶으면 end 입력) : ')\n",
    "    \n",
    "  return df_output\n",
    "\n",
    "def paper_citation(df):\n",
    "  keyword = []\n",
    "  keyword.append(input('특허번호 입력 :')) \n",
    "  str_keyword =\"\".join(keyword)\n",
    "  keyowrd_url = 'https://patents.google.com/patent/'+ str_keyword\n",
    "\n",
    "  data = requests.get(keyowrd_url)\n",
    "  soup = BeautifulSoup(data.content, 'html.parser')\n",
    "  country = soup.find_all('tr',{'itemprop':'backwardReferences'})\n",
    "  information = []\n",
    "  non_patent_citation = soup.find_all('tr',{'itemprop':'detailedNonPatentLiterature'}) \n",
    "  NPC = []\n",
    "\n",
    "  for n in non_patent_citation:\n",
    "       NPC.append(n.get_text())\n",
    "  \n",
    "  non_patent = \"\".join(NPC)\n",
    "  non_patent = non_patent.replace(\"\\n\",\"\")\n",
    "  new_non_patent = non_patent.split(\"*\")\n",
    "  del new_non_patent[len(new_non_patent)-1]\n",
    "\n",
    "  for n in country:\n",
    "    information.append(n.get_text())\n",
    "\n",
    "  indexlist = []\n",
    "  for i,data in enumerate(information):\n",
    "    index = 0\n",
    "    while index > -1:\n",
    "      index = data.find('\\n',index)\n",
    "      if index > -1:\n",
    "        indexlist.append(index)\n",
    "        index += len('\\n')\n",
    "\n",
    "  publication_number = []\n",
    "  priority_date = []\n",
    "  publication_date = []\n",
    "  assignee = []\n",
    "  title = []\n",
    "  line = ''\n",
    "  count = 0\n",
    "\n",
    "  for i,index in enumerate(indexlist):\n",
    "    if index == 0:\n",
    "      line = information[count]\n",
    "      publication_number.append(line[indexlist[i+2]+1:indexlist[i+3]])\n",
    "      if line.find('*')==-1:\n",
    "        priority_date.append(line[indexlist[i+6]+1:indexlist[i+7]])\n",
    "        publication_date.append(line[indexlist[i+7]+1:indexlist[i+8]])\n",
    "        assignee.append(line[indexlist[i+8]+1:indexlist[i+9]])\n",
    "        title.append(line[indexlist[i+9]+1:indexlist[i+10]])\n",
    "      else :\n",
    "        priority_date.append(line[indexlist[i+7]+1:indexlist[i+8]])\n",
    "        publication_date.append(line[indexlist[i+8]+1:indexlist[i+9]])\n",
    "        assignee.append(line[indexlist[i+9]+1:indexlist[i+10]])\n",
    "        title.append(line[indexlist[i+10]+1:indexlist[i+11]])\n",
    "      count = count + 1\n",
    "    \n",
    "\n",
    "\n",
    "  df2 = pd.DataFrame(index=range(0,len(publication_number)), columns=['Publication number', 'Priority date', 'Publication date','Assignee','Title'])\n",
    "  df2['Publication number'] = publication_number\n",
    "  df2['Priority date'] = priority_date\n",
    "  df2['Publication date'] = publication_date\n",
    "  df2['Assignee'] = assignee\n",
    "  df2['Title'] = title\n",
    "\n",
    "  df3 = pd.DataFrame(index=range(0,len(new_non_patent)), columns=['Non-Patent Citations title'])\n",
    "  df3['Non-Patent Citations title'] = new_non_patent\n",
    "  return df2, df3\n",
    "\n",
    "\n",
    "def Data_File(keyword,df):\n",
    "  file_name = ''\n",
    "  for i in range(len(keyword)):\n",
    "    file_name = file_name + keyword[i] + ' '\n",
    "  file_name = file_name+'.xlsx'\n",
    "  excel_name = ''\n",
    "  excel_name = file_name.replace('end','')\n",
    "    # print(excel_name)\n",
    "  df.to_excel(excel_name,index =False)\n",
    "  \n",
    "  \n",
    "def Search_patent_news():\n",
    "  #검색할 키워드 입력\n",
    "  query = input('검색할 키워드를 입력하세요: ')\n",
    "\n",
    "\n",
    "  #크롬드라이버로 원하는 url로 접속\n",
    "  url = 'https://www.patentlyapple.com/patently-apple/'\n",
    "  chrome_options = webdriver.ChromeOptions()\n",
    "  chrome_options.add_argument('--headless')\n",
    "  chrome_options.add_argument('--no-sandbox')\n",
    "  chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "  driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
    "  driver.get(url)\n",
    "  time.sleep(3)\n",
    "\n",
    "  #검색창에 키워드 입력 후 엔터\n",
    "\n",
    "  search_box = driver.find_element_by_css_selector(\"#search-blog > div > input\")\n",
    "  search_box.send_keys(query)\n",
    "  search_box.send_keys(Keys.RETURN)\n",
    "  time.sleep(3)\n",
    "\n",
    "  Apple_Patent_news = []\n",
    "  Apple_Patent_link = []\n",
    "  for k in range(0,100):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    Patent__apple_title = soup.find_all('h3', attrs={'class': 'entry-header font-entryheader'})\n",
    "    for i in Patent__apple_title:\n",
    "      Apple_Patent_news.append(i.get_text())\n",
    "\n",
    "    Patent__apple_link = soup.select('h3 > a')\n",
    "    for i in Patent__apple_link:\n",
    "        Apple_Patent_link.append(i.attrs['href'])\n",
    "\n",
    "    try:\n",
    "      if(k==0):\n",
    "        driver.find_element_by_xpath('//*[@id=\"post-container\"]/div/div[1]/div[1]/div/div/div[3]/div[11]/div/span').click()\n",
    "      if(k > 0):\n",
    "        driver.find_element_by_xpath('//*[@id=\"post-container\"]/div/div[1]/div[1]/div/div/div[3]/div[11]/div/span[3]/a').click()\n",
    "    except NoSuchElementException :\n",
    "      print(\"Maximum page is \", k+1)\n",
    "      break\n",
    "  time.sleep(2)\n",
    "  driver.close()\n",
    "\n",
    "  df = pd.DataFrame(index=range(0,len(Apple_Patent_news)), columns=['News_Title','News_Link'])\n",
    "  df['News_Title'] = Apple_Patent_news\n",
    "  df['News_Link'] = Apple_Patent_link\n",
    "\n",
    "  return df\n",
    "\n",
    "def search_details(wholeurl):\n",
    "  driver = webdriver.Chrome('./chromedriver')\n",
    "  patent_name = []\n",
    "  inventor = []\n",
    "  assignee = []\n",
    "  summary = []\n",
    "\n",
    "  # 첫 페이지에 접속\n",
    "  tempurl = wholeurl.replace('&page=*','')\n",
    "  driver.get(tempurl)\n",
    "  time.sleep(2)\n",
    "\n",
    "  html = driver.page_source\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "  notices = soup.select('#htmlContent')\n",
    "  try:\n",
    "    count = soup.select_one('#count > div.layout.horizontal.style-scope.search-results > span.flex.style-scope.search-results > span:nth-child(3)').text\n",
    "  except:\n",
    "    count = 1000\n",
    "  count = count.replace(',','')\n",
    "\n",
    "  # 논문제목, inventor, assignee추출\n",
    "  for i, n in enumerate(notices):\n",
    "      if i%4 == 0:\n",
    "          patent_name.append(n.text.strip())\n",
    "      elif i%4 == 1:\n",
    "          inventor.append(n.text.strip())\n",
    "      elif i%4 == 2:\n",
    "          assignee.append(n.text.strip())\n",
    "      else :\n",
    "          summary.append(n.text.strip())\n",
    "  # 적용국가, 특허코드 추출\n",
    "  object = soup.select('#resultsContainer > section > search-result-item > article > div > div > div > div.flex.style-scope.search-result-item > h4.metadata.style-scope.search-result-item > span')\n",
    "  ob = []\n",
    "  for o in object:\n",
    "      ob.append(o.text)  \n",
    "  applied_country = ''\n",
    "  country = []\n",
    "  patent_code = []\n",
    "  for o in ob:\n",
    "      count1 = o.count('\\n')\n",
    "      if count1 == 0:\n",
    "          applied_country = applied_country + o + ', '\n",
    "      if count1 == 4:\n",
    "          applied_country = applied_country[:-2]\n",
    "          country.append(applied_country)\n",
    "          applied_country = ''\n",
    "          patent_code.append(o.replace('\\n',''))\n",
    "\n",
    "  # 검색결과가 1000개이상 나오지않아서 오래걸리는 것을 방지\n",
    "  page = int(count)/10\n",
    "  if page > 99:\n",
    "      page = 99\n",
    "\n",
    "  # 첫 페이지에서 확인한 정보로 나머지 페이지 확인\n",
    "  for i in range(1,int(page)+1):\n",
    "      tempurl = wholeurl.replace('&page=*','&page=')+f'{i}'\n",
    "      driver.get(tempurl)\n",
    "      rand_value = randint(1,3)\n",
    "      time.sleep(rand_value)\n",
    "      \n",
    "      html = driver.page_source\n",
    "      soup = BeautifulSoup(html, 'html.parser')\n",
    "      notices = soup.select('#htmlContent')   \n",
    "      \n",
    "      object = soup.select('#resultsContainer > section > search-result-item > article > div > div > div > div.flex.style-scope.search-result-item > h4.metadata.style-scope.search-result-item > span')\n",
    "      ob = []\n",
    "      for o in object:\n",
    "          ob.append(o.text)  \n",
    "\n",
    "      applied_country = ''\n",
    "      for o in ob:\n",
    "          count = o.count('\\n')\n",
    "          if count == 0:\n",
    "              applied_country = applied_country + o + ', '\n",
    "          if count == 4:\n",
    "              applied_country = applied_country[:-2]\n",
    "              country.append(applied_country)\n",
    "              applied_country = ''\n",
    "              patent_code.append(o.replace('\\n',''))\n",
    "\n",
    "      for i, n in enumerate(notices):\n",
    "          if i%4 == 0:\n",
    "              patent_name.append(n.text.strip())\n",
    "          elif i%4 == 1:\n",
    "              inventor.append(n.text.strip())\n",
    "          elif i%4 == 2:\n",
    "              assignee.append(n.text.strip())\n",
    "          else :\n",
    "              summary.append(n.text.strip())\n",
    "\n",
    "  driver.close()\n",
    "  return patent_name, patent_code, inventor, assignee ,country\n",
    "\n",
    "# 데이터 프레임 생성\n",
    "def search_details_df(patent_name, patent_code, inventor, assignee ,country):\n",
    "    output = pd.DataFrame({'특허제목':patent_name, '특허코드':patent_code, 'inventor':inventor, 'assignee':assignee, '적용국가':country})\n",
    "    return output\n",
    "\n",
    "# google patent 링크 생성함수 (en:english, kr:korean) 제목또한 해당 언어로 return\n",
    "def google_link(list,language):\n",
    "    base_link = 'https://patents.google.com/patent/'\n",
    "    output_link = []\n",
    "    for l in list:\n",
    "        output_link.append(base_link+l+'/'+language)\n",
    "    \n",
    "    return output_link\n",
    "\n",
    "def whole_name(link):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0', 'X-Requested-With': 'XMLHttpRequest'}  \n",
    "    whole_names = []\n",
    "    dates = []\n",
    "    pdf_link = []\n",
    "    patent_citation_num = []\n",
    "    n1 = []\n",
    "    n2 = []\n",
    "    for l in link:\n",
    "        data = requests.get(l, headers=headers)\n",
    "        soup = BeautifulSoup(data.content, 'html.parser')\n",
    "        try:\n",
    "          title = soup.select_one('body > search-app > article > h1').text\n",
    "        except:\n",
    "          title = ' - no title - '\n",
    "        try:\n",
    "          date = soup.find(attrs = {'itemprop':'publicationDate'}).text\n",
    "        except:\n",
    "          date = '-'\n",
    "        ptnum = soup.select('body > search-app > article > section > h2')\n",
    "        \n",
    "        st = title.find(' - ')\n",
    "        end = title.rfind(' - ')\n",
    "        whole_names.append(title[st+3:end-9])\n",
    "        dates.append(date)\n",
    "        link2 = soup.find('a')\n",
    "        pdf_link.append(link2.attrs['href'])\n",
    "        \n",
    "        for p in ptnum:\n",
    "            if p.text.find('Patent Citations ')==0:\n",
    "                str1 = p.text\n",
    "                n1 = re.findall('\\(([^)]+)', str1)\n",
    "            if p.text.find('Non-Patent Citations')==0:\n",
    "                str2 = p.text\n",
    "                n2 = re.findall('\\(([^)]+)', str2)\n",
    "            num = 0\n",
    "            if n1:\n",
    "                num = num + int(n1[0])\n",
    "            if n2:\n",
    "                num = num + int(n2[0])\n",
    "        patent_citation_num.append(num)\n",
    "\n",
    "    return whole_names, dates, pdf_link, patent_citation_num\n",
    "\n",
    "def change_ptname(df):\n",
    "    google_links = google_link(df['특허코드'],'en')\n",
    "    whole_names, dates, pdf_link, patent_citation_num = whole_name(google_links)\n",
    "    \n",
    "    \n",
    "    df['특허제목'] = whole_names\n",
    "    df['google patent link'] = google_links\n",
    "    df['출원날짜'] = dates\n",
    "    df['pdf link'] = pdf_link\n",
    "    df['인용횟수'] = patent_citation_num\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "def Search_patent_news():\n",
    "  #검색할 키워드 입력\n",
    "  query = input('검색할 키워드를 입력하세요: ')\n",
    "\n",
    "\n",
    "  #크롬드라이버로 원하는 url로 접속\n",
    "  driver = webdriver.Chrome('./chromedriver')\n",
    "  url = 'https://www.patentlyapple.com/patently-apple/'\n",
    "  driver.get(url)\n",
    "  time.sleep(2)\n",
    "\n",
    "  #검색창에 키워드 입력 후 엔터\n",
    "\n",
    "  search_box = driver.find_element_by_css_selector(\"#search-blog > div > input\")\n",
    "  search_box.send_keys(query)\n",
    "  search_box.send_keys(Keys.RETURN)\n",
    "  time.sleep(2)\n",
    "\n",
    "  Apple_Patent_news = []\n",
    "  Apple_Patent_link = []\n",
    "  for k in range(0,100):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    Patent__apple_title = soup.find_all('h3', attrs={'class': 'entry-header font-entryheader'})\n",
    "    for i in Patent__apple_title:\n",
    "      Apple_Patent_news.append(i.get_text())\n",
    "\n",
    "    Patent__apple_link = soup.select('h3 > a')\n",
    "    for i in Patent__apple_link:\n",
    "        Apple_Patent_link.append(i.attrs['href'])\n",
    "\n",
    "    try:\n",
    "      if(k==0):\n",
    "        driver.find_element_by_xpath('//*[@id=\"post-container\"]/div/div[1]/div[1]/div/div/div[3]/div[11]/div/span').click()\n",
    "      if(k > 0):\n",
    "        driver.find_element_by_xpath('//*[@id=\"post-container\"]/div/div[1]/div[1]/div/div/div[3]/div[11]/div/span[3]/a').click()\n",
    "    except NoSuchElementException :\n",
    "      print(\"Maximum page is \", k+1)\n",
    "      break\n",
    "  driver.close()\n",
    "\n",
    "  df = pd.DataFrame(index=range(0,len(Apple_Patent_news)), columns=['News_Title','News_Link'])\n",
    "  df['News_Title'] = Apple_Patent_news\n",
    "  df['News_Link'] = Apple_Patent_link\n",
    "\n",
    "  return df\n",
    "\n",
    "def detail_search(keyword, inventor, assignee, country):\n",
    "    baseurl = 'https://patents.google.com/?q='\n",
    "    # wholeurl = baseurl + keyword + '&inventor=' + inventor + '&assignee=' + assignee + '&country=' + country + '&page=*'\n",
    "    wholeurl = baseurl + keyword + '&inventor=' + inventor + '&assignee=' + assignee + '&page=*'\n",
    "    \n",
    "    patent_name, patent_code, inventor, assignee ,country = search_details(wholeurl)\n",
    "    output = search_details_df(patent_name, patent_code, inventor, assignee ,country)\n",
    "    output2 = change_ptname(output)\n",
    "    \n",
    "    return output2\n",
    "  \n",
    "# 제목과 링크 추출\n",
    "def extractlink(url):\n",
    "  # url = 'https://www.patentlyapple.com/patently-apple/autonomous-vehicle-technology/'\n",
    "  driver = webdriver.Chrome('./chromedriver')\n",
    "  driver.get(url)\n",
    "  time.sleep(3)\n",
    "\n",
    "  Apple_Patent_news = []\n",
    "  Apple_Patent_link = []\n",
    "  title_index=0\n",
    "  for k in range(0,10):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    Patent__apple_title = soup.find_all('h2', attrs={'class': 'entry-header font-entryheader'})\n",
    "\n",
    "    for i in Patent__apple_title:\n",
    "      Apple_Patent_news.append(i.get_text()[2:-2])\n",
    "    Patent__apple_link = soup.select('h2 > span > a')\n",
    "    for i in Patent__apple_link:\n",
    "        Apple_Patent_link.append(i.attrs['href'])\n",
    "\n",
    "    try:\n",
    "      if(len(Apple_Patent_link)==25*(k+1)):\n",
    "        # page_str = 'https://www.patentlyapple.com/patently-apple/autonomous-vehicle-technology/' + 'page/'+ str(k+1) + '/'\n",
    "        page_str = url + 'page/'+ str(k+1) + '/'\n",
    "        driver.get(page_str)\n",
    "      if(len(Apple_Patent_link)<25*(k+1)):\n",
    "        raise Exception\n",
    "    except Exception:\n",
    "      print(\"Maximum page is \", k)\n",
    "      break\n",
    "  time.sleep(2)\n",
    "  driver.close()\n",
    "\n",
    "  df1 = pd.DataFrame(index=range(0,len(Apple_Patent_news)), columns=['News_Title','News_Link'])\n",
    "  df1['News_Title'] = Apple_Patent_news\n",
    "  df1['News_Link'] = Apple_Patent_link\n",
    "  return df1\n",
    "\n",
    "# 첫번째필터\n",
    "def filter1(df):\n",
    "    driver = webdriver.Chrome('./chromedriver')\n",
    "    patents_list = []\n",
    "    link_list = []\n",
    "    for i in df.index:\n",
    "        # 웹페이지 가져오기\n",
    "        link = df['News_Link'][i]\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        contents = soup.select('#post-container > div.container > div.row.pagebody > div.col-sm-8.col-sm-push-4.col-md-6.col-md-push-3 > div > div > article > div.entry-more.font-entrybody > p')\n",
    "        contents_list = []\n",
    "        befor_list = patents_list[:]\n",
    "        patents_list_un = []\n",
    "        for c in contents:\n",
    "            contents_list.append(c.text)\n",
    "        # html의 한 구조체마다 반복문\n",
    "        for j, con in enumerate(contents_list):\n",
    "            # 첫번째 필터를 통해 데이터 추출\n",
    "            c = ','\n",
    "            lst = []\n",
    "            # 구조체에서의 ,위치 return\n",
    "            for pos,char in enumerate(con):\n",
    "                if(char == c):\n",
    "                    lst.append(pos)\n",
    "            for i, l in enumerate(lst):\n",
    "                before = 0\n",
    "                now = l\n",
    "                if i!=0:\n",
    "                    before = lst[i-1]\n",
    "                if (now - before) == 4:\n",
    "                    patents_list_un.append(contents_list[j][before-3:now+4])\n",
    "            \n",
    "            # 두번째 필터를 통해 데이터 추출\n",
    "            pos1 = con.find('20210')\n",
    "            if pos1 != -1:\n",
    "                patents_list.append(con[pos1:pos1+11])\n",
    "            pos2 = con.find('20200')\n",
    "            if pos2 != -1:\n",
    "                patents_list.append(con[pos2:pos2+11])\n",
    "            pos3 = con.find('20190')\n",
    "            if pos3 != -1:\n",
    "                patents_list.append(con[pos3:pos3+11])\n",
    "            pos4 = con.find('20180')\n",
    "            if pos4 != -1:\n",
    "                patents_list.append(con[pos4:pos4+11])\n",
    "      \n",
    "        \n",
    "        for code in patents_list_un:\n",
    "            try:\n",
    "                if ((code[0]==' ')&code[1:3].isdigit()&code[4:7].isdigit()&code[8:11].isdigit()):\n",
    "                    # print(code[1:])\n",
    "                    patents_list.append(code[1:].replace(',',''))\n",
    "                # print(patents_list)\n",
    "            except IndexError:\n",
    "                a=0\n",
    "        \n",
    "        # 세번째 필터를 통해 데이터 추출\n",
    "        Patent_title_number= soup.select('div > p > a')\n",
    "        Patent_title_here = soup.select('div > p > span > a')\n",
    "        \n",
    "        for k in Patent_title_number:\n",
    "            if k.attrs['href'].find('uspto') != -1:\n",
    "                if k.find('patentnumber') != -1:\n",
    "                    patents_list.append(k.attrs['href'].replace(',','')[-8:])\n",
    "                else: \n",
    "                    patents_list.append(k.attrs['href'].replace(',','')[-11:])\n",
    "        for k in Patent_title_here:\n",
    "            if k.attrs['href'].find('uspto') != -1:\n",
    "                if k.find('patentnumber') != -1:\n",
    "                    patents_list.append(k.attrs['href'].replace(',','')[-8:])\n",
    "                else: \n",
    "                    patents_list.append(k.attrs['href'].replace(',','')[-11:])\n",
    "        \n",
    "        if (len(befor_list) == len(patents_list)):\n",
    "            link_list.append(link)\n",
    "            # print(link)\n",
    "\n",
    "    return patents_list\n",
    "\n",
    "def applelink(codes):\n",
    "    links = []\n",
    "    for code in codes:\n",
    "        links.append('https://patents.google.com/patent/US'+code)\n",
    "    return links\n",
    "\n",
    "def application2(url):\n",
    "  data = requests.get(url)\n",
    "  soup = BeautifulSoup(data.content, 'html.parser')\n",
    "  country = soup.find_all('span', attrs={'itemprop': 'countryCode'})\n",
    "  Date = soup.find_all('span', attrs={'itemprop': 'filingDate'})\n",
    "  nation_name = []\n",
    "  nation_date = []\n",
    "  # ----------------특허 적용 국가 리스트----------------  \n",
    "  for n in country:\n",
    "    try:\n",
    "      nation_name.append(n.get_text())\n",
    "    except:\n",
    "      nation_name.append('')\n",
    "  country_name =  [] \n",
    "  for i in nation_name:\n",
    "    try:\n",
    "      country_name.append(i)\n",
    "    except:\n",
    "      country_name.append('')\n",
    "  for n in Date:\n",
    "    try:\n",
    "      nation_date.append(n.get_text())\n",
    "    except:\n",
    "      nation_date.append('')\n",
    "  country_date =  [] \n",
    "  for i in nation_date:\n",
    "      country_date.append(i)\n",
    "  \n",
    "  new_contryName = []\n",
    "  new_contryDate = []\n",
    "  for i,v in enumerate(country_date):\n",
    "    new_contryDate.append(v[:4])\n",
    "  for i in range(len(new_contryDate)):\n",
    "    try:\n",
    "      new_contryName.append(country_name[-1-i])\n",
    "    except:\n",
    "      new_contryName.append('')\n",
    "  new_contryName.reverse()\n",
    "\n",
    "  df_application = []\n",
    "  for i in range(len(new_contryName)):\n",
    "    df_application.append(new_contryName[i]+'('+new_contryDate[i]+')')\n",
    "\n",
    "  df_output = []\n",
    "  df_output.append(' / '.join(df_application))\n",
    "\n",
    "  inventor = soup.find_all('dd',{'itemprop':'inventor'})\n",
    "  assigneeCurrent = soup.find_all('dd',{'itemprop':'assigneeCurrent'})  \n",
    "  patent_inventor = []\n",
    "  patent_assignee = []\n",
    "\n",
    "  for n in inventor:\n",
    "      patent_inventor.append(n.get_text())\n",
    "\n",
    "  df_patent_inventor = []\n",
    "  for i in range(len(patent_inventor)):\n",
    "    if i == 0:\n",
    "      df_patent_inventor.append(patent_inventor[i])\n",
    "    else :\n",
    "      df_patent_inventor.append(' / '+patent_inventor[i])\n",
    "  df_patent_inventor= \"\".join(df_patent_inventor)\n",
    "\n",
    "  for n in assigneeCurrent:\n",
    "      patent_assignee.append(n.get_text())\n",
    "  df_patent_assignee = []\n",
    "  for i in range(len(patent_assignee)):\n",
    "    if i ==0:\n",
    "      df_patent_assignee.append(patent_assignee[i])\n",
    "    else :\n",
    "      df_patent_assignee.append(' / '+patent_assignee[i])\n",
    "\n",
    "  Str_assignee = \"\".join(df_patent_assignee)\n",
    "  Str_assignee = Str_assignee.replace(\"\\n\",\"\")\n",
    "  Str_assignee = Str_assignee.lstrip()\n",
    "  new_list_assignee = Str_assignee.split(\"   \")\n",
    "  new_list_assignee= \"\".join(new_list_assignee)\n",
    "  try:\n",
    "    title = soup.select_one('body > search-app > article > h1').text\n",
    "    st = title.find(' - ')\n",
    "    end = title.rfind(' - ')\n",
    "    df1 = pd.DataFrame(index=range(0,1), columns=['특허제목','특허코드','적용국가','Inventor','assignee'])\n",
    "    df1['특허제목'] = title[st+3:end-9]\n",
    "    df1['특허코드'] = title[:st]\n",
    "    df1['적용국가'] = df_output\n",
    "    df1['Inventor'] = df_patent_inventor\n",
    "    df1['assignee'] = new_list_assignee\n",
    "  except AttributeError:\n",
    "    df1 = pd.DataFrame(index=range(0,1), columns=['특허제목','특허코드','적용국가','Inventor','assignee'])\n",
    "    df1['특허제목'] = 'Withdrawn'\n",
    "    df1['특허코드'] = url[-10:]\n",
    "    df1['적용국가'] = '-'\n",
    "    df1['Inventor'] = '-'\n",
    "    df1['assignee'] = '-'\n",
    "  return df1\n",
    "\n",
    "def search_from_googlelinks(links):\n",
    "    df2 = pd.DataFrame(columns=['특허제목','특허코드','적용국가','Inventor','assignee'])\n",
    "    for link in links:\n",
    "        df1 = application2(link)\n",
    "        df2 = pd.concat([df2, df1], ignore_index=True)\n",
    "\n",
    "    return df2\n",
    "  \n",
    "def Search_patent_news():\n",
    "  #검색할 키워드 입력\n",
    "  query = input('검색할 키워드를 입력하세요: ')\n",
    "\n",
    "\n",
    "  #크롬드라이버로 원하는 url로 접속\n",
    "  driver = webdriver.Chrome('./chromedriver')\n",
    "  url = 'https://www.patentlyapple.com/patently-apple/'\n",
    "  driver.get(url)\n",
    "  time.sleep(2)\n",
    "\n",
    "  #검색창에 키워드 입력 후 엔터\n",
    "\n",
    "  search_box = driver.find_element_by_css_selector(\"#search-blog > div > input\")\n",
    "  search_box.send_keys(query)\n",
    "  search_box.send_keys(Keys.RETURN)\n",
    "  time.sleep(2)\n",
    "\n",
    "  Apple_Patent_news = []\n",
    "  Apple_Patent_link = []\n",
    "  for k in range(0,100):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    Patent__apple_title = soup.find_all('h3', attrs={'class': 'entry-header font-entryheader'})\n",
    "    for i in Patent__apple_title:\n",
    "      Apple_Patent_news.append(i.get_text())\n",
    "\n",
    "    Patent__apple_link = soup.select('h3 > a')\n",
    "    for i in Patent__apple_link:\n",
    "        Apple_Patent_link.append(i.attrs['href'])\n",
    "\n",
    "    try:\n",
    "      if(k==0):\n",
    "        driver.find_element_by_xpath('//*[@id=\"post-container\"]/div/div[1]/div[1]/div/div/div[3]/div[11]/div/span').click()\n",
    "      if(k > 0):\n",
    "        driver.find_element_by_xpath('//*[@id=\"post-container\"]/div/div[1]/div[1]/div/div/div[3]/div[11]/div/span[3]/a').click()\n",
    "    except NoSuchElementException :\n",
    "      print(\"Maximum page is \", k+1)\n",
    "      break\n",
    "  driver.close()\n",
    "\n",
    "  df = pd.DataFrame(index=range(0,len(Apple_Patent_news)), columns=['News_Title','News_Link'])\n",
    "  df['News_Title'] = Apple_Patent_news\n",
    "  df['News_Link'] = Apple_Patent_link\n",
    "\n",
    "  return df\n",
    "\n",
    "def applepatent(url):\n",
    "    # 제목과 링크 추출\n",
    "    dflink = extractlink(url)\n",
    "    \n",
    "    # 필터들을 통해 얻어낸 코드리스트와 걸러지지않은 링크들\n",
    "    list2 = filter1(dflink)\n",
    "    \n",
    "    # 코드 링크로의 구글 링크로의 변환\n",
    "    links = applelink(list(set(list2)))\n",
    "    \n",
    "    # 구글에서 검색을 통한 데이터프레임생성\n",
    "    df_output = search_from_googlelinks(links)\n",
    "    \n",
    "    return df_output\n",
    "  \n",
    "def applepatent_keyword():\n",
    "    # 제목과 링크 추출\n",
    "    dflink = Search_patent_news()\n",
    "    \n",
    "    # 필터들을 통해 얻어낸 코드리스트와 걸러지지않은 링크들\n",
    "    list2 = filter1(dflink)\n",
    "    \n",
    "    # 코드 링크로의 구글 링크로의 변환\n",
    "    links = applelink(list(set(list2)))\n",
    "    \n",
    "    # 구글에서 검색을 통한 데이터프레임생성\n",
    "    df_output = search_from_googlelinks(links)\n",
    "    \n",
    "    return df_output\n",
    "\n",
    "def df_to_db(keyword, df, client):\n",
    "    items = df.to_dict(\"records\")\n",
    "    mydb = client['data']\n",
    "    mycol = mydb[keyword]\n",
    "    \n",
    "    mycol.insert_many(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#how to use function1\n",
    "\n",
    "key = 'stradvision, autonomous driving, CNN'\n",
    "\n",
    "keywords, df = search(key,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#how to use function2\n",
    "\n",
    "keyword = 'CNN,deep learning,autonomous driving'\n",
    "\n",
    "inventor = '김계현'\n",
    "\n",
    "assignee = 'stradvision'\n",
    "\n",
    "country = 'kr'\n",
    "\n",
    "df2 = detail_search(keyword, inventor, assignee, country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to use function3\n",
    "\n",
    "url = 'https://www.patentlyapple.com/patently-apple/autonomous-vehicle-technology/'\n",
    "\n",
    "df3 = applepatent(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_client = MongoClient(\"mongodb://localhost:27017/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db에 에플을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.patentlyapple.com/patently-apple/autonomous-vehicle-technology/'\n",
    "df = applepatent(url)\n",
    "df_to_db('autonomous driving1',df,my_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db에 키워드들을 저장\n",
    "(리스트를 수정해서 돌리면 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'autonomous driving'\n",
    "inventor = ''\n",
    "assignee_list = ['stradvision','Waymo LLC','Nvidia','argo AI','baidu','cruise','motional','Mobileye','Aurora','zoox','nuro','ford','intel','Hyundai Motor Company','volkswagen','yandex','daimler','bosch','aptiv','toyota','renault','nissan','mitsubishi motors']\n",
    "country = '' \n",
    "for assignee in assignee_list:\n",
    "    df = detail_search(keyword, inventor, assignee, country)\n",
    "    df_to_db('autonomous driving1',df,my_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ford 중간에 끊김 (connection error)\n",
    "\n",
    "그 이후로 실행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'autonomous driving'\n",
    "inventor = ''\n",
    "assignee_list = ['ford','intel','Hyundai Motor Company','volkswagen','yandex','daimler','bosch','aptiv','toyota','renault','nissan','mitsubishi motors']\n",
    "country = '' \n",
    "for assignee in assignee_list:\n",
    "    df = detail_search(keyword, inventor, assignee, country)\n",
    "    df_to_db('autonomous driving1',df,my_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_35996/3201541700.py:315: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('./chromedriver')\n"
     ]
    }
   ],
   "source": [
    "keyword = 'autonomous driving'\n",
    "inventor = ''\n",
    "assignee_list = ['stradvision']\n",
    "country = '' \n",
    "for assignee in assignee_list:\n",
    "    df = detail_search(keyword, inventor, assignee, country)\n",
    "    df_to_db('autonomous driving_test',df,my_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('autonomous driving.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.pop('_id')\n",
    "df.drop_duplicates(ignore_index=True)\n",
    "df.to_csv('autonomous driving.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inventor</th>\n",
       "      <th>assignee</th>\n",
       "      <th>적용국가</th>\n",
       "      <th>특허제목</th>\n",
       "      <th>특허코드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James R. Wilson / Christopher D. Jones</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>US(2019) / US(2019)</td>\n",
       "      <td>Sensor enclosure and glass panels for sensor e...</td>\n",
       "      <td>US10852395B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gregory E. Rogers / Charles L. Greenlee</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>US(2016) / US(2016)</td>\n",
       "      <td>Ultrasonic sensor</td>\n",
       "      <td>US10871555B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peter F. Masschelein / Martin Melcher / Derek ...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>US(2020) / US(2018) / US(2020)</td>\n",
       "      <td>Systems with windows</td>\n",
       "      <td>US11180005B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>US00255002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Romain A. Teil / Jack J. WANDERMAN / Dominic P...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>US(2020) / US(2017) / US(2020)</td>\n",
       "      <td>Cosmetic Integration of Displa</td>\n",
       "      <td>US20200214148A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>JP</td>\n",
       "      <td>Motor-cooling device</td>\n",
       "      <td>JP2002204550A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14432</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>JP</td>\n",
       "      <td>Piston assembling device</td>\n",
       "      <td>JPH10138060A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14433</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>EP, US, JP, KR, DE</td>\n",
       "      <td>Cylinder fuel injection type internal combusti...</td>\n",
       "      <td>JPH11294157A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14434</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>US, KR, DE, SE</td>\n",
       "      <td>\\n  Device for a suction system as well as way...</td>\n",
       "      <td>SE510904C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14435</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>JP</td>\n",
       "      <td>Electric power steering device</td>\n",
       "      <td>JP2004098796A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14436 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Inventor  \\\n",
       "0                 James R. Wilson / Christopher D. Jones   \n",
       "1                Gregory E. Rogers / Charles L. Greenlee   \n",
       "2      Peter F. Masschelein / Martin Melcher / Derek ...   \n",
       "3                                                      -   \n",
       "4      Romain A. Teil / Jack J. WANDERMAN / Dominic P...   \n",
       "...                                                  ...   \n",
       "14431                                                NaN   \n",
       "14432                                                NaN   \n",
       "14433                                                NaN   \n",
       "14434                                                NaN   \n",
       "14435                                                NaN   \n",
       "\n",
       "                     assignee                            적용국가  \\\n",
       "0                 Apple Inc               US(2019) / US(2019)   \n",
       "1                 Apple Inc               US(2016) / US(2016)   \n",
       "2                 Apple Inc    US(2020) / US(2018) / US(2020)   \n",
       "3                           -                               -   \n",
       "4                 Apple Inc    US(2020) / US(2017) / US(2020)   \n",
       "...                       ...                             ...   \n",
       "14431  Mitsubishi Motors Corp                              JP   \n",
       "14432  Mitsubishi Motors Corp                              JP   \n",
       "14433  Mitsubishi Motors Corp              EP, US, JP, KR, DE   \n",
       "14434  Mitsubishi Motors Corp                  US, KR, DE, SE   \n",
       "14435  Mitsubishi Motors Corp                              JP   \n",
       "\n",
       "                                                    특허제목             특허코드  \n",
       "0      Sensor enclosure and glass panels for sensor e...     US10852395B1  \n",
       "1                                      Ultrasonic sensor     US10871555B1  \n",
       "2                                   Systems with windows     US11180005B2  \n",
       "3                                              Withdrawn       US00255002  \n",
       "4                         Cosmetic Integration of Displa  US20200214148A1  \n",
       "...                                                  ...              ...  \n",
       "14431                               Motor-cooling device    JP2002204550A  \n",
       "14432                           Piston assembling device     JPH10138060A  \n",
       "14433  Cylinder fuel injection type internal combusti...     JPH11294157A  \n",
       "14434  \\n  Device for a suction system as well as way...       SE510904C2  \n",
       "14435                     Electric power steering device    JP2004098796A  \n",
       "\n",
       "[14436 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:471: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['특허제목'] = whole_names\n",
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['google patent link'] = google_links\n",
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:473: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['출원날짜'] = dates\n",
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:474: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pdf link'] = pdf_link\n",
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:475: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['인용횟수'] = patent_citation_num\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='patents.google.com', port=443): Max retries exceeded with url: /patent/US10826786B2/en (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001AF5122B610>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    175\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             raise NewConnectionError(\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001AF5122B610>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='patents.google.com', port=443): Max retries exceeded with url: /patent/US10826786B2/en (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001AF5122B610>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_41716/1954130576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdf_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdf_temp_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_ptname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_temp_new\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_41716/742750843.py\u001b[0m in \u001b[0;36mchange_ptname\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchange_ptname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[0mgoogle_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoogle_link\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'특허코드'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m     \u001b[0mwhole_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpdf_link\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatent_citation_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhole_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoogle_links\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_41716/742750843.py\u001b[0m in \u001b[0;36mwhole_name\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0mn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='patents.google.com', port=443): Max retries exceeded with url: /patent/US10826786B2/en (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001AF5122B610>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다'))"
     ]
    }
   ],
   "source": [
    "# df = change_ptname(df)\n",
    "n = len(df.index)\n",
    "print(n/100)\n",
    "df2 = pd.DataFrame(columns=['특허제목','특허코드','적용국가','Inventor','assignee','google patent link','출원날짜','pdf link','인용횟수'])\n",
    "for i in range(1,int(n/100) + 2):\n",
    "    df_temp = df.loc[(i-1)*100:i*100-1]\n",
    "    if i==int(n/100)+1:\n",
    "        df_temp = df.loc[(i-1)*100:n]\n",
    "    df_temp_new = change_ptname(df_temp)\n",
    "    df2 = pd.concat([df2,df_temp_new], ignore_index=True)\n",
    "    time.sleep(3)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:471: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['특허제목'] = whole_names\n",
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['google patent link'] = google_links\n",
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:473: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['출원날짜'] = dates\n",
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:474: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pdf link'] = pdf_link\n",
      "C:\\Users\\junki\\AppData\\Local\\Temp/ipykernel_41716/742750843.py:475: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['인용횟수'] = patent_citation_num\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "# df = change_ptname(df)\n",
    "n = len(df.index)\n",
    "print(n/100)\n",
    "# df2 = pd.DataFrame(columns=['특허제목','특허코드','적용국가','Inventor','assignee','google patent link','출원날짜','pdf link','인용횟수'])\n",
    "# change here !!!\n",
    "for i in range(128,int(n/100) + 2):\n",
    "    df_temp = df.loc[(i-1)*100:i*100-1]\n",
    "    if i==int(n/100)+1:\n",
    "        df_temp = df.loc[(i-1)*100:n]\n",
    "    df_temp_new = change_ptname(df_temp)\n",
    "    df2 = pd.concat([df2,df_temp_new], ignore_index=True)\n",
    "    time.sleep(3)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>특허제목</th>\n",
       "      <th>특허코드</th>\n",
       "      <th>적용국가</th>\n",
       "      <th>Inventor</th>\n",
       "      <th>assignee</th>\n",
       "      <th>google patent link</th>\n",
       "      <th>출원날짜</th>\n",
       "      <th>pdf link</th>\n",
       "      <th>인용횟수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sensor enclosure and glass panels for sensor e...</td>\n",
       "      <td>US10852395B1</td>\n",
       "      <td>US(2019) / US(2019)</td>\n",
       "      <td>James R. Wilson / Christopher D. Jones</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>https://patents.google.com/patent/US10852395B1/en</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>https://patentimages.storage.googleapis.com/54...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ultrasonic sensor</td>\n",
       "      <td>US10871555B1</td>\n",
       "      <td>US(2016) / US(2016)</td>\n",
       "      <td>Gregory E. Rogers / Charles L. Greenlee</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>https://patents.google.com/patent/US10871555B1/en</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>https://patentimages.storage.googleapis.com/0f...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Systems with windows</td>\n",
       "      <td>US11180005B2</td>\n",
       "      <td>US(2020) / US(2018) / US(2020)</td>\n",
       "      <td>Peter F. Masschelein / Martin Melcher / Derek ...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>https://patents.google.com/patent/US11180005B2/en</td>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>https://patentimages.storage.googleapis.com/4d...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>US00255002</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://patents.google.com/patent/US00255002/en</td>\n",
       "      <td>-</td>\n",
       "      <td>//www.google.com/</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cosmetic Integration of Displa</td>\n",
       "      <td>US20200214148A1</td>\n",
       "      <td>US(2020) / US(2017) / US(2020)</td>\n",
       "      <td>Romain A. Teil / Jack J. WANDERMAN / Dominic P...</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>https://patents.google.com/patent/US2020021414...</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>https://patentimages.storage.googleapis.com/81...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13734</th>\n",
       "      <td>Motor-cooling device</td>\n",
       "      <td>JP2002204550A</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>https://patents.google.com/patent/JP2002204550...</td>\n",
       "      <td>2002-07-19</td>\n",
       "      <td>/patent/JP2002204550A/ja</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13735</th>\n",
       "      <td>Piston assembling device</td>\n",
       "      <td>JPH10138060A</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>https://patents.google.com/patent/JPH10138060A/en</td>\n",
       "      <td>1998-05-26</td>\n",
       "      <td>/patent/JPH10138060A/ja</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13736</th>\n",
       "      <td>Cylinder fuel injection type internal combusti...</td>\n",
       "      <td>JPH11294157A</td>\n",
       "      <td>EP, US, JP, KR, DE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>https://patents.google.com/patent/JPH11294157A/en</td>\n",
       "      <td>1999-10-26</td>\n",
       "      <td>/patent/JPH11294157A/ja</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13737</th>\n",
       "      <td>\\n  Device for a suction system as well as way...</td>\n",
       "      <td>SE510904C2</td>\n",
       "      <td>US, KR, DE, SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>https://patents.google.com/patent/SE510904C2/en</td>\n",
       "      <td>1999-07-05</td>\n",
       "      <td>/patent/SE510904C2/sv</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13738</th>\n",
       "      <td>Electric power steering device</td>\n",
       "      <td>JP2004098796A</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitsubishi Motors Corp</td>\n",
       "      <td>https://patents.google.com/patent/JP2004098796...</td>\n",
       "      <td>2004-04-02</td>\n",
       "      <td>https://patentimages.storage.googleapis.com/c5...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13739 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    특허제목             특허코드  \\\n",
       "0      Sensor enclosure and glass panels for sensor e...     US10852395B1   \n",
       "1                                      Ultrasonic sensor     US10871555B1   \n",
       "2                                   Systems with windows     US11180005B2   \n",
       "3                                                              US00255002   \n",
       "4                         Cosmetic Integration of Displa  US20200214148A1   \n",
       "...                                                  ...              ...   \n",
       "13734                               Motor-cooling device    JP2002204550A   \n",
       "13735                           Piston assembling device     JPH10138060A   \n",
       "13736  Cylinder fuel injection type internal combusti...     JPH11294157A   \n",
       "13737  \\n  Device for a suction system as well as way...       SE510904C2   \n",
       "13738                     Electric power steering device    JP2004098796A   \n",
       "\n",
       "                                 적용국가  \\\n",
       "0                 US(2019) / US(2019)   \n",
       "1                 US(2016) / US(2016)   \n",
       "2      US(2020) / US(2018) / US(2020)   \n",
       "3                                   -   \n",
       "4      US(2020) / US(2017) / US(2020)   \n",
       "...                               ...   \n",
       "13734                              JP   \n",
       "13735                              JP   \n",
       "13736              EP, US, JP, KR, DE   \n",
       "13737                  US, KR, DE, SE   \n",
       "13738                              JP   \n",
       "\n",
       "                                                Inventor  \\\n",
       "0                 James R. Wilson / Christopher D. Jones   \n",
       "1                Gregory E. Rogers / Charles L. Greenlee   \n",
       "2      Peter F. Masschelein / Martin Melcher / Derek ...   \n",
       "3                                                      -   \n",
       "4      Romain A. Teil / Jack J. WANDERMAN / Dominic P...   \n",
       "...                                                  ...   \n",
       "13734                                                NaN   \n",
       "13735                                                NaN   \n",
       "13736                                                NaN   \n",
       "13737                                                NaN   \n",
       "13738                                                NaN   \n",
       "\n",
       "                     assignee  \\\n",
       "0                 Apple Inc     \n",
       "1                 Apple Inc     \n",
       "2                 Apple Inc     \n",
       "3                           -   \n",
       "4                 Apple Inc     \n",
       "...                       ...   \n",
       "13734  Mitsubishi Motors Corp   \n",
       "13735  Mitsubishi Motors Corp   \n",
       "13736  Mitsubishi Motors Corp   \n",
       "13737  Mitsubishi Motors Corp   \n",
       "13738  Mitsubishi Motors Corp   \n",
       "\n",
       "                                      google patent link        출원날짜  \\\n",
       "0      https://patents.google.com/patent/US10852395B1/en  2020-12-01   \n",
       "1      https://patents.google.com/patent/US10871555B1/en  2020-12-22   \n",
       "2      https://patents.google.com/patent/US11180005B2/en  2021-11-23   \n",
       "3        https://patents.google.com/patent/US00255002/en           -   \n",
       "4      https://patents.google.com/patent/US2020021414...  2020-07-02   \n",
       "...                                                  ...         ...   \n",
       "13734  https://patents.google.com/patent/JP2002204550...  2002-07-19   \n",
       "13735  https://patents.google.com/patent/JPH10138060A/en  1998-05-26   \n",
       "13736  https://patents.google.com/patent/JPH11294157A/en  1999-10-26   \n",
       "13737    https://patents.google.com/patent/SE510904C2/en  1999-07-05   \n",
       "13738  https://patents.google.com/patent/JP2004098796...  2004-04-02   \n",
       "\n",
       "                                                pdf link 인용횟수  \n",
       "0      https://patentimages.storage.googleapis.com/54...    8  \n",
       "1      https://patentimages.storage.googleapis.com/0f...   24  \n",
       "2      https://patentimages.storage.googleapis.com/4d...   13  \n",
       "3                                      //www.google.com/   13  \n",
       "4      https://patentimages.storage.googleapis.com/81...   13  \n",
       "...                                                  ...  ...  \n",
       "13734                           /patent/JP2002204550A/ja    5  \n",
       "13735                            /patent/JPH10138060A/ja    5  \n",
       "13736                            /patent/JPH11294157A/ja    5  \n",
       "13737                              /patent/SE510904C2/sv    5  \n",
       "13738  https://patentimages.storage.googleapis.com/c5...    5  \n",
       "\n",
       "[13739 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "돌려보고 안되면 i직접 바꿔가면서 15번 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('autonomous_driving.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_db('autonomous driving refined(same name removed)',df2, my_client)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0b38cae232899e4cc19d3d28f862922099138c5816621f18394cafec0ce0a1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
